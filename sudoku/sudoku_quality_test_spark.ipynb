{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sudoku Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import numpy as np\n",
    "from helpers.data_prep_and_print import print_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .config(\"spark.executor.memory\", \"4g\")\n",
    "       .config(\"spark.driver.memory\", \"2g\")\n",
    "       .appName(\"Sudoku Quality Checks\")\n",
    "       .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame using an ifered Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"../sudoku_data/\"\n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .csv(path+\"sudoku_1_mio_sequenced_columns.csv\")\n",
    "#df = df.limit(10)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All cells are filled => no Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All numbers must be between 0 and 9 for the quizzes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_conditions = []\n",
    "# Iterate over all quizzes col names \n",
    "for col_name in df.columns[:81]:\n",
    "    query_conditions.append (\"(\" + col_name + \" >= 0 ) and (\" + col_name+ \" <= 9 )\")\n",
    "df = df.filter(\" and \".join(query_conditions))\n",
    "#print_df (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions must contain numbers between 1 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_conditions = []\n",
    "# Iterate over all col names with solutions \n",
    "for col_name in df.columns[81:]:\n",
    "    query_conditions.append (\"(\" + col_name + \" > 0 ) and (\" + col_name + \" <=9 )\")\n",
    "df = df.filter(\" and \".join(query_conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All cells != 0 must have identical content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Query\n",
    "query_conditions = [] \n",
    "num_cols = int(len(df.columns)/2 )\n",
    "for i in range(num_cols):\n",
    "     query_conditions.append (\"(\"+df.columns[i]+ \" == 0 or \" + df.columns[i] +\" == \"+df.columns[i+num_cols]+\")\")\n",
    "df = df.filter(\" and \".join(query_conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Solutions: Checking all Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking each row\n",
    "#start = 81\n",
    "#import pandas as pd\n",
    "#from pyspark import Series\n",
    "def is_in_range_and_unique(values:list, min_val:int, max_val:int)-> bool:\n",
    "    \"\"\"Check if the list given contains only unique elements\"\"\"\n",
    "    if len(values) == len(set(values)):\n",
    "        return min(values) == min_val and max(values)== max_val \n",
    "    return False\n",
    "\n",
    "def check_unique_num_in_row_and_col(row: Row) -> bool:\n",
    "    \"\"\"Input: pd.Series, Output boolean\"\"\"\n",
    "    begin_solution = 81\n",
    "    for start in range(begin_solution,len(row),9):\n",
    "        if not is_in_range_and_unique (row[start:start+9],1,9):\n",
    "            return False\n",
    "    for start in range(begin_solution,begin_solution+9):\n",
    "        list_of_indexes = [*range (start,len(row),9)]\n",
    "        list_of_values = [row[x] for x in list_of_indexes]\n",
    "        if not is_in_range_and_unique (list_of_values,1,9):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "df = df.rdd.filter(lambda x: check_unique_num_in_row_and_col(x)).toDF()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Solutions: Checking all Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check square\n",
    "# there are nine 3x3 squares \n",
    "# the first square has the indexes (S1A, S1B, S1C, \n",
    "#                                   S2A, S2B, S2C,\n",
    "#                                   S3A, S3B, S3C)\n",
    "\n",
    "def get_square_definition ():\n",
    "    \"\"\"Returns the square positions of a 9*9 sodoku\"\"\"\n",
    "    col_names = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\"] \n",
    "    row_nums = [*range(1,10)]\n",
    "\n",
    "    col_chunks = np.array_split(col_names, 3)\n",
    "    row_chunks = np.array_split(row_nums, 3)\n",
    "    square_pos=[]\n",
    "    for curr_rows in row_chunks :\n",
    "        for curr_cols in col_chunks:\n",
    "            pos_names = []        \n",
    "            for curr_row in curr_rows :\n",
    "                for curr_col in curr_cols:\n",
    "                    pos_names.append(\"S\"+str(curr_row)+str(curr_col))\n",
    "            square_pos.append(pos_names)\n",
    "    return square_pos       \n",
    "\n",
    "def check_squares(row:Row) -> bool:\n",
    "    \"\"\"Input=pd.Series Output = True/False\"\"\"\n",
    "    for curr_square in get_square_definition() :\n",
    "        list_of_values = [row[x] for x in curr_square] \n",
    "        if not is_in_range_and_unique(list_of_values,1,9):\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "df = df.rdd.filter(lambda x: check_squares(x)).toDF()\n",
    "print(df.count())\n",
    "print_df(df,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
